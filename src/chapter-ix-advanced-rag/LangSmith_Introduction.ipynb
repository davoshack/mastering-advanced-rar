{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain LangSmith and LangChain Hub\n",
    "\n",
    "-   Find the  [Notebook](https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2008%20-%20LangSmith_Introduction.ipynb)  for this section at  [towardsai.net/book](http://towardsai.net/book).\n",
    "\n",
    "üí°While LangChain is appropriate for initial prototyping, LangSmith provides a setting for debugging, testing, and refining LLM applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LangSmith](https://www.langchain.com/langsmith)  is a platform for evaluating and monitoring the quality of LLM systems‚Äô outputs. Its functionality includes tracking metadata, token usage, and execution time, which is vital for managing resources effectively.\n",
    "\n",
    "LangSmith improves the efficiency and performance of new chains and tools. It also provides visualization tools to recognize response patterns and trends, enhancing the understanding and analysis of performance. It allows users to create customized testing environments tailored to specific requirements, enabling comprehensive evaluation under various conditions. The platform also tracks the executions linked to an active instance and allows for the testing and assessing of any prompts or responses produced. LangSmith offers several tutorials and in-depth documentation to assist users in getting started.\n",
    "\n",
    "On the other hand, LangChain Hub is a platform designed for the development, storage, and sharing of reusable components used in building applications with large language models (LLMs). It offers a repository of modules such as prompts, chains, and agents that can be easily accessed and integrated into projects. LangChain Hub simplifies the creation of LLM-driven applications by providing tools and templates and promoting collaboration among developers.\n",
    "\n",
    "This section contains an example of how to use LangChain Hub together with a question-answering chain in LangChain. We will guide you through the setup process for LangChain, including installing necessary libraries and configuring environment variables. A LangSmith account is required for certain features like tracing. Detailed steps for setting up a new account will be provided.\n",
    "\n",
    "First, you will need an API key. Navigate to the  [LangSmith](https://www.langchain.com/langsmith)  website and register for an account. Find the option to generate an API key on the settings page. Click the ‚ÄúGenerate API Key‚Äù button to receive your API key.\n",
    "\n",
    "Install the necessary libraries using the command `!pip install -q langchain==0.0.346 openai==1.3.7 tiktoken==0.5.2 cohere==4.37 deeplake==3.8.11 langchainhub==0.1.14`.\n",
    "\n",
    "Configure the environment with the API keys for OpenAI, which will be used in the embedding generation process, and the Activeloop key, which will be used to store data in the cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advanced_rag_custom_utils.helper import (\n",
    "    get_openai_api_key, \n",
    "    get_activeloop_api_key, \n",
    "    get_langchain_api_key,\n",
    "    get_langchain_project,\n",
    "    get_langchain_tracing_v2,\n",
    "    get_langchain_endpoint,\n",
    ")\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "ACTIVELOOP_API_KEY = get_activeloop_api_key()\n",
    "\n",
    "LANGCHAIN_API_KEY = get_langchain_api_key()\n",
    "LANGCHAIN_TRACING_V2 = get_langchain_tracing_v2()\n",
    "LANGCHAIN_PROJECT = get_langchain_project()\n",
    "LANGCHAIN_ENDPOINT = get_langchain_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how to commit a prompt to the LangChain Hub by adding it to your handle‚Äôs namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\")\n",
    "\n",
    "handle = \"<YOUR_USERNAME>\"\n",
    "hub.push(f\"{handle}/rag-prompt\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you update the prompt, you can push the modified prompt to the same key to ‚Äúcommit‚Äù a new version of the prompt during evaluation. Let‚Äôs say we want to add a system message to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may try making other changes and saving them in a new commit.\n",
    "from langchain import schema\n",
    "\n",
    "prompt.messages.insert(0,\n",
    "   schema.SystemMessage(\n",
    "       content=\"You are a precise, autoregressive question-answering system.\"\n",
    "   )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most recent version of the prompt is kept as the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pushing to the same prompt \"repo\" will create a new commit\n",
    "hub.push(f\"{handle}/rag-prompt\", prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mastering-advanced-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
